<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-LLM Knowledge Enhancement and Agent RAG System Optimization</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        .header {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            box-shadow: 0 2px 20px rgba(0,0,0,0.1);
        }

        .nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 2rem;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: bold;
            color: #667eea;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        .logo-text {
            font-size: 1.2rem;
            transition: all 0.3s ease;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-links a {
            text-decoration: none;
            color: #333;
            font-weight: 500;
            transition: color 0.3s;
        }

        .nav-links a:hover {
            color: #667eea;
        }

        .lang-switch {
            background: #667eea;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s;
        }

        .lang-switch:hover {
            background: #5a6fd8;
            transform: translateY(-2px);
        }

        /* Hero Section */
        .hero {
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: center;
            color: white;
            position: relative;
        }

        .hero-content h1 {
            font-size: 3.5rem;
            margin-bottom: 1rem;
            animation: fadeInUp 1s ease-out;
        }

        .hero-content p {
            font-size: 1.2rem;
            margin-bottom: 2rem;
            animation: fadeInUp 1s ease-out 0.3s both;
        }

        .cta-button {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 2px solid white;
            padding: 1rem 2rem;
            border-radius: 50px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s;
            animation: fadeInUp 1s ease-out 0.6s both;
        }

        .cta-button:hover {
            background: white;
            color: #667eea;
            transform: translateY(-3px);
        }

        /* Sections */
        .section {
            padding: 5rem 0;
            opacity: 0;
            transform: translateY(50px);
            transition: all 0.6s;
        }

        .section.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .section:nth-child(even) {
            background: rgba(255, 255, 255, 0.9);
        }

        .section:nth-child(odd) {
            background: rgba(255, 255, 255, 0.95);
        }

        .section-title {
            font-size: 2.5rem;
            text-align: center;
            margin-bottom: 3rem;
            color: #667eea;
        }

        /* Bold text styling */
        .bold {
            font-weight: bold;
            color: #5a6fd8;
        }

        .bold_white {
            font-weight: bold;
            color: white;
        }

        .content-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-bottom: 2rem;
        }

        .content-card {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: all 0.3s;
        }

        .content-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0,0,0,0.15);
        }

        .content-card h3 {
            color: #667eea;
            margin-bottom: 1rem;
            font-size: 1.3rem;
        }

        .content-card ul {
            padding-left: 1.5rem;
        }

        .content-card li {
            margin-bottom: 0.5rem;
        }

        /* Images */
        .image-container {
            text-align: center;
            margin: 2rem 0;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .image-caption {
            margin-top: 1rem;
            font-style: italic;
            color: #666;
            font-size: 0.9rem;
            text-align: center;
        }

        /* Wide image for system architecture */
        .wide-image-container {
            text-align: center;
            margin: 3rem 0;
        }

        .wide-image-container img {
            max-width: 100%;
            width: 90%;
            height: auto;
            border-radius: 15px;
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        .image-row {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 2rem;
            margin-top: 2rem;
            justify-items: center;
        }

        .image-item {
            text-align: center;
            max-width: 400px;
        }

        .image-item img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            aspect-ratio: auto;
            object-fit: contain;
        }

        .image-item-no-circle {
            text-align: center;
        }

        .image-item-no-circle img {
            max-width: 100%;
            height: auto;
            border-radius: 0px;
            aspect-ratio: auto;
            object-fit: contain;
        }

        /* Methodology specific styles */
        .methodology-intro {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 3rem;
            text-align: center;
            font-size: 1.2rem;
        }

        .methodology-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 3rem;
            align-items: start;
        }

        .methodology-tabs {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .methodology-tab {
            background: white;
            padding: 1.5rem;
            border-radius: 15px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            cursor: pointer;
            transition: all 0.3s;
            border-left: 4px solid transparent;
        }

        .methodology-tab:hover {
            transform: translateX(5px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
        }

        .methodology-tab.active {
            border-left-color: #667eea;
            background: linear-gradient(135deg, #f8f9ff, #ffffff);
            transform: translateX(10px);
        }

        .methodology-tab h3 {
            color: #667eea;
            margin-bottom: 0.5rem;
            font-size: 1.2rem;
        }

        .methodology-visual {
            position: sticky;
            top: 120px;
            text-align: center;
        }

        .methodology-image {
            opacity: 0;
            transform: translateY(20px);
            transition: all 0.5s;
            display: none;
        }

        .methodology-image.active {
            opacity: 1;
            transform: translateY(0);
            display: block;
        }

        .methodology-image img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        /* Experiment section styles */
        .experiment-grid-1 {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-bottom: 3rem;
        }

        .experiment-grid-2 {
            margin-bottom: 3rem;
        }

        .experiment-wide-card {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: all 0.3s;
            grid-column: 1 / -1;
        }

        .experiment-wide-card h3 {
            color: #667eea;
            margin-bottom: 1.5rem;
            font-size: 1.3rem;
        }

        .experiment-wide-card ul {
            padding-left: 1.5rem;
            margin-bottom: 2rem;
        }

        .experiment-wide-card li {
            margin-bottom: 0.5rem;
        }

        .experiment-grid-3 {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
        }

        .experiment-grid-3 h3 {
            color: #667eea;
            margin-bottom: 1.5rem;
            font-size: 1.3rem;
        }

        .experiment-grid-3 ul {
            padding-left: 1.5rem;
            margin-bottom: 2rem;
        }

        .experiment-grid-3 li {
            margin-bottom: 0.5rem;
        }

        .media-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-top: 2rem;
        }

        .video-container {
            position: relative;
            text-align: center;
        }

        .video-player {
            width: 100%;
            max-width: 100%;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .video-preview {
            width: 100%;
            height: 200px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: all 0.3s;
        }

        .video-preview:hover {
            transform: scale(1.02);
        }

        /* Contribution section styles */
        .contribution-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 2rem;
        }

        /* Language Toggle */
        .lang-content {
            display: none;
        }

        .lang-content.active {
            display: block;
        }

        /* Animations */
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(50px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Responsive */
        @media (max-width: 1024px) {
            .logo-text {
                font-size: 1rem;
            }
        }

        @media (max-width: 768px) {
            .nav {
                flex-direction: column;
                gap: 1rem;
            }

            .nav-links {
                flex-direction: column;
                text-align: center;
                gap: 1rem;
            }

            .hero-content h1 {
                font-size: 2.5rem;
            }

            .section-title {
                font-size: 2rem;
            }

            .content-grid {
                grid-template-columns: 1fr;
            }

            .methodology-content {
                grid-template-columns: 1fr;
                gap: 2rem;
            }

            .methodology-visual {
                position: static;
            }

            .experiment-grid-1 {
                grid-template-columns: 1fr;
            }

            .media-container {
                grid-template-columns: 1fr;
            }

            .contribution-grid {
                grid-template-columns: 1fr;
            }

            .image-row {
                grid-template-columns: 1fr;
            }

            .wide-image-container img {
                width: 95%;
            }

            .logo {
                font-size: 1.2rem;
                justify-content: center;
            }
            
            .logo-text {
                font-size: 0.9rem;
                max-width: 200px;
            }
        }

        @media (max-width: 480px) {
            .logo-text {
                max-width: 150px;
            }
        }

        /* Footer */
        .footer {
            background: #333;
            color: white;
            text-align: center;
            padding: 2rem;
        }

        /* Image Modal */
        .image-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.9);
            z-index: 1000;
            cursor: pointer;
        }

        .modal-content {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            max-width: 90%;
            max-height: 90vh;
            object-fit: contain;
            transition: transform 0.3s ease;
        }

        .modal-content:hover {
            transform: translate(-50%, -50%) scale(1.05);
        }

        .close-modal {
            position: absolute;
            top: 15px;
            right: 35px;
            color: #f1f1f1;
            font-size: 40px;
            font-weight: bold;
            cursor: pointer;
            z-index: 1001;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <nav class="nav container">
            <div class="logo" data-en="Multi-LLM Knowledge Enhancement" data-zh="多模型知识增强研究">
                <i class="fas fa-brain"></i> 
                <span id="logoText" class="logo-text">Multi-LLM Knowledge Enhancement</span>
            </div>
            <ul class="nav-links">
                <li><a href="#background" data-en="Background" data-zh="研究背景">Background</a></li>
                <li><a href="#methodology" data-en="Methodology" data-zh="研究方法">Methodology</a></li>
                <li><a href="#experiment" data-en="Experiment" data-zh="实验分析">Experiment</a></li>
                <li><a href="#contribution" data-en="Contribution" data-zh="主要贡献">Contribution</a></li>
            </ul>
            <button class="lang-switch" onclick="toggleLanguage()">
                <i class="fas fa-language"></i> <span id="langText">中文</span>
            </button>
        </nav>
    </header>

    
    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-content">
            <div class="lang-content active" id="en-hero">
                <h1>Multi-LLM Knowledge Enhancement and Agent RAG System Optimization</h1>
                <p>For Educational Applications</p>
            </div>
            <div class="lang-content" id="zh-hero">
                <h1>面向教育场景的多模型知识增强与智能体系统优化研究</h1>
                <p>提升检索生成增强系统在高等教育中的应用效果</p>
            </div>
            <a href="#background" class="cta-button">
                <i class="fas fa-arrow-down"></i> Explore Research
            </a>
        </div>
    </section>

    <!-- Background Section -->
    <section id="background" class="section">
        <div class="container">
            <div class="lang-content active" id="en-background">
                <!-- System Architecture Comparison -->
                <div class="wide-image-container">
                    <img src="./images/fig0_system_architecture_comparison.png" alt="System Architecture Comparison">
                    <div class="image-caption">Comparison of the system architecture diagrams of a traditional Retrieval Augmentation Generation (RAG) system and a RAG Chatbot System Based On Multiple Model Synthetic Q&A Generation Comparison and Integration. Prior to inference, knowledge is extracted and augmented based on course document content using Multiple LLMs and a high quality Q&A set is generated for downstream retrieval.</div>
                </div>

                <h2 class="section-title">Background & Objective</h2>
                <div class="content-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-exclamation-triangle"></i> Current Challenges</h3>
                        <ul>
                            <li>Traditional <span class="bold">RAG systems</span> suffer from <span class="bold">heterogeneous document formats</span> and <span class="bold">noise interference</span></li>
                            <li><span class="bold">Improper segmentation strategies</span> lead to <span class="bold">low retrieval accuracy</span></li>
                            <li>Severe <span class="bold">hallucination problems</span> in course-specific knowledge scenarios</li>
                            <li>Limited effectiveness when handling <span class="bold">proprietary educational content</span></li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-target"></i> Research Objectives</h3>
                        <ul>
                            <li>Construct <span class="bold">high-quality course-specific knowledge bases</span></li>
                            <li>Generate <span class="bold">structured Q&A knowledge bases</span> through <span class="bold">multi-model collaborative knowledge distillation</span></li>
                            <li>Enhance <span class="bold">RAG system retrieval accuracy</span> for educational applications</li>
                            <li>Validate <span class="bold">methodology effectiveness</span> in real educational scenarios</li>
                        </ul>
                    </div>
                </div>
                
                <!-- 
                =================== 图片路径替换说明 ===================
                以下图片路径需要根据部署环境进行替换：
                
                1. 本地开发环境：
                   - 创建 ./images/ 文件夹
                   - 将图片放入该文件夹
                   - 使用相对路径：./images/fig1_traditional_rag_problems.jpg
                
                2. GitHub Pages部署：
                   - 将图片上传到仓库的 images/ 文件夹
                   - 使用相对路径：./images/fig1_traditional_rag_problems.jpg
                   - 或使用GitHub raw链接：https://raw.githubusercontent.com/your-username/repo-name/main/images/fig1_traditional_rag_problems.jpg
                
                3. Netlify/Vercel等云端部署：
                   - 将图片放在项目的 public/images/ 或 images/ 文件夹
                   - 使用相对路径：./images/fig1_traditional_rag_problems.jpg
                
                4. 使用CDN或云存储：
                   - 上传到阿里云OSS、AWS S3、腾讯云COS等
                   - 使用完整URL：https://your-bucket.oss-region.aliyuncs.com/images/fig1_traditional_rag_problems.jpg
                
                建议的图片命名规范：
                - fig1_traditional_rag_problems.jpg/png
                - fig2_llm_hallucination_examples.jpg/png
                - fig3_methodology_generation.jpg/png
                - fig4_evaluation_framework.jpg/png
                - fig5_voting_mechanism.jpg/png
                - fig6_kb_optimization.jpg/png
                - fig7_performance_comparison.jpg/png
                - fig8_retrieval_accuracy.jpg/png
                - fig9_text_quality_results.jpg/png
                - demo_video.mp4
                =================== 图片路径替换说明结束 ===================
                -->

                <div class="image-row">
                    <div class="image-item">
                        <img src="./images/fig1_llm_hallucination_examples.png" alt="LLM Hallucination Examples">
                        <div class="image-caption">Examples of LLM lacking critical knowledge in Course-specific Queries. When a student asked about ELEC3442 project requirements, LLM gaves generic hardware design steps, not the course-specific details. </div>
                    </div>
                    <div class="image-item">
                        <img src="./images/fig2_traditional_rag_problems.png" alt="Traditional RAG Problems">
                        <div class="image-caption">Challenges of traditional RAG systems in the knowledge base building process</div>
                    </div>
                </div>
            </div>
            <div class="lang-content" id="zh-background">
                <!-- System Architecture Comparison -->
                <div class="wide-image-container">
                    <img src="./images/fig0_system_architecture_comparison.png" alt="系统架构比较">
                    <div class="image-caption">传统检索增强生成（RAG）系统与基于多模型合成问答生成比较集成的RAG聊天机器人系统的系统架构图比较。在推理之前，使用多个LLM基于课程文档内容提取和增强知识，并生成高质量的问答集用于下游检索。</div>
                </div>

                <h2 class="section-title">研究背景与目标</h2>
                <div class="content-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-exclamation-triangle"></i> 现有挑战</h3>
                        <ul>
                            <li>传统<span class="bold">RAG系统</span>存在<span class="bold">文档格式异构</span>、<span class="bold">噪声干扰</span>等问题</li>
                            <li><span class="bold">分割策略不当</span>导致<span class="bold">检索精度低下</span></li>
                            <li>在课程专有知识场景中<span class="bold">幻觉问题严重</span></li>
                            <li>处理<span class="bold">教育专有内容</span>时效果有限</li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-target"></i> 研究目标</h3>
                        <ul>
                            <li>构建<span class="bold">高质量的课程专用知识库</span></li>
                            <li>通过<span class="bold">多模型协同知识蒸馏</span>生成<span class="bold">结构化问答知识库</span></li>
                            <li>提升<span class="bold">RAG系统在教育应用中的检索准确性</span></li>
                            <li>验证方法在实际教育场景中的<span class="bold">有效性</span></li>
                        </ul>
                    </div>
                </div>
                <div class="image-row">
                    <div class="image-item">
                        <img src="./images/fig1_llm_hallucination_examples.png" alt="LLM Hallucination Examples">
                        <div class="image-caption">LLM 在特定课程问题中缺乏关键知识的示例。当一名学生询问 ELEC3442 项目要求时，LLM 只提供了一般的硬件设计步骤，而没有提供特定课程的详细信息。</div>
                    </div>
                    <div class="image-item">
                        <img src="./images/fig2_traditional_rag_problems.png" alt="Traditional RAG Problems">
                        <div class="image-caption">传统RAG系统在知识库构建过程中的挑战</div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Methodology Section -->
    <section id="methodology" class="section">
        <div class="container">
            <div class="lang-content active" id="en-methodology">
                <h2 class="section-title">Methodology</h2>
                <div class="methodology-intro">
                    This research proposes an innovative <span class="bold_white">"Multi-LLM Synthetic Q&A Generation, Comparison, and Integration"</span> pipeline with a core workflow of <span class="bold_white">"generate → evaluate → compare → integrate"</span>.
                </div>
                <div class="methodology-content">
                    <div class="methodology-tabs">
                        <div class="methodology-tab active" data-tab="1">
                            <h3><i class="fas fa-cogs"></i> Multi-Model Collaborative Generation</h3>
                            <p>Utilizes five frontier LLMs (<span class="bold">Claude Sonnet 4</span>, <span class="bold">Gemini 2.5 Pro</span>, <span class="bold">DeepSeek R1</span>, <span class="bold">ChatGPT o3</span>, <span class="bold">Grok 4</span>) with <span class="bold">Chain-of-Thought prompts</span> to extract meta-knowledge and generate self-contained Q&A pairs.</p>
                        </div>
                        <div class="methodology-tab" data-tab="2">
                            <h3><i class="fas fa-chart-line"></i> Quantitative Evaluation Framework</h3>
                            <p>Designs comprehensive assessment system encompassing <span class="bold">text quality metrics</span> (readability, coherence, technical term density) and <span class="bold">retrieval accuracy metrics</span> (recall, precision). Through comprehensive evaluation, we select a high-quality Q&A knowledge base produced through <span class="bold">knowledge distillation</span> as the foundation for subsequent integration.</p>
                        </div>
                        <div class="methodology-tab" data-tab="3">
                            <h3><i class="fas fa-vote-yea"></i> Cross-Model Voting Mechanism</h3>
                            <p>Employs <span class="bold">semantic similarity comparison</span> and <span class="bold">voting mechanisms</span> to filter and integrate complementary Q&A pairs from different models. High-quality Q&A pairs selected through voting mechanisms must have <span class="bold">semantic similarity < 10%</span> with existing Q&A knowledge base to ensure diversity and prevent redundancy.</p>
                        </div>
                        <div class="methodology-tab" data-tab="4">
                            <h3><i class="fas fa-database"></i> Knowledge Base Optimization</h3>
                            <p>Applies <span class="bold">rule-based segmentation strategies</span> for generated structured Q&A pairs, replacing traditional <span class="bold">automatic segmentation methods</span> to achieve optimal knowledge base construction.</p>
                        </div>
                    </div>
                    <div class="methodology-visual">
                        <div class="methodology-image active" data-image="1">
                            <img src="./images/fig3_methodology.png" alt="Multi-Model Generation">
                            <div class="image-caption">Multi-LLM Collaborative Q&A Generation Process</div>
                        </div>
                        <div class="methodology-image" data-image="2">
                            <img src="./images/fig4_evaluation_framework.png" alt="Evaluation Framework">
                            <div class="image-caption">Comprehensive Quantitative Evaluation Framework</div>
                        </div>
                        <div class="methodology-image" data-image="3">
                            <img src="./images/fig5_voting_mechanism.png" alt="Voting Mechanism">
                            <div class="image-caption">Cross-Model Voting and Integration Mechanism</div>
                        </div>
                        <div class="methodology-image" data-image="4">
                            <img src="./images/fig6_kb_optimization.png" alt="Knowledge Base Optimization">
                            <div class="image-caption">Rule-based Knowledge Base Optimization Strategy</div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="lang-content" id="zh-methodology">
                <h2 class="section-title">研究方法</h2>
                <div class="methodology-intro">
                    本研究提出了创新的<span class="bold_white">"多模型合成问答生成、比较与集成"</span>管道，核心流程为<span class="bold_white">"生成→评估→比较→集成"</span>。
                </div>
                <div class="methodology-content">
                    <div class="methodology-tabs">
                        <div class="methodology-tab active" data-tab="1">
                            <h3><i class="fas fa-cogs"></i> 多模型协同生成</h3>
                            <p>采用五个前沿LLM（<span class="bold">Claude Sonnet 4</span>、<span class="bold">Gemini 2.5 Pro</span>、<span class="bold">DeepSeek R1</span>、<span class="bold">ChatGPT o3</span>、<span class="bold">Grok 4</span>），使用<span class="bold">链式思维提示词</span>提取元知识并生成自包含问答对。</p>
                        </div>
                        <div class="methodology-tab" data-tab="2">
                            <h3><i class="fas fa-chart-line"></i> 量化评估框架</h3>
                            <p>设计综合评估系统，涵盖<span class="bold">文本质量指标</span>（可读性、连贯性、技术术语密度等）和<span class="bold">检索准确性指标</span>（召回率、精确率）。通过综合评估，选出一个通过<span class="bold">知识蒸馏</span>产出的高质量Q&A知识集作为后续集成的基础。</p>
                        </div>
                        <div class="methodology-tab" data-tab="3">
                            <h3><i class="fas fa-vote-yea"></i> 跨模型投票机制</h3>
                            <p>采用<span class="bold">语义相似度比较</span>和<span class="bold">投票机制</span>，筛选并整合来自不同模型的互补性问答对。通过投票机制选出的高质量Q&A需要与现有Q&A知识集的<span class="bold">语义相似度<10%</span>，以确保多样性和避免冗余。</p>
                        </div>
                        <div class="methodology-tab" data-tab="4">
                            <h3><i class="fas fa-database"></i> 知识库优化</h3>
                            <p>对生成的结构化问答对采用<span class="bold">基于规则的分割策略</span>，替代传统<span class="bold">自动分割方法</span>，实现最优的知识库构建。</p>
                        </div>
                    </div>
                    <div class="methodology-visual">
                        <div class="methodology-image active" data-image="1">
                            <img src="./images/fig3_methodology.png" alt="Multi-Model Generation">
                            <div class="image-caption">多模型协同问答生成流程</div>
                        </div>
                        <div class="methodology-image" data-image="2">
                            <img src="./images/fig4_evaluation_framework.png" alt="Evaluation Framework">
                            <div class="image-caption">综合量化评估框架</div>
                        </div>
                        <div class="methodology-image" data-image="3">
                            <img src="./images/fig5_voting_mechanism.png" alt="Voting Mechanism">
                            <div class="image-caption">跨模型投票与集成机制</div>
                        </div>
                        <div class="methodology-image" data-image="4">
                            <img src="./images/fig6_kb_optimization.png" alt="Knowledge Base Optimization">
                            <div class="image-caption">基于规则的知识库优化策略</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Experiment Section -->
    <section id="experiment" class="section">
        <div class="container">
            <div class="lang-content active" id="en-experiment">
                <h2 class="section-title">Experiment & Analysis</h2>
                
                <!-- First Row -->
                <div class="experiment-grid-1">
                    <div class="content-card">
                        <h3><i class="fas fa-file-alt"></i> Dataset</h3>
                        <ul>
                            <li><span class="bold">11 documents</span> from <span class="bold">ELEC3442 Embedded System</span> course</li>
                            <li><span class="bold">286 benchmark queries</span> for evaluation</li>
                            <li>Comprehensive testing across <span class="bold">diverse question types</span></li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-chart-bar"></i> Performance Metrics</h3>
                        <ul>
                            <li>Comprehensive evaluation across <span class="bold">text quality</span> and <span class="bold">retrieval metrics</span></li>
                            <li><span class="bold">LLM-as-Judge</span> evaluation framework</li>
                            <li>Consistent improvements across diverse educational scenarios</li>
                        </ul>
                    </div>
                </div>

                <!-- Second Row -->
                <div class="experiment-grid-2">
                    <div class="experiment-wide-card">
                        <h3><i class="fas fa-trophy"></i> Text Quality Enhancement</h3>
                        <ul>
                            <li><span class="bold">Gemini 2.5 Pro</span> achieved optimal <span class="bold">readability performance</span></li>
                            <li><span class="bold">Claude Sonnet 4</span> and <span class="bold">DeepSeek R1</span> led in <span class="bold">content richness</span></li>
                            <li>Significant improvements in <span class="bold">text coherence</span> and <span class="bold">technical depth</span></li>
                        </ul>
                        <div class="image-row">
                            <div class="image-item-no-circle">
                                <img src="./images/fig7_text readability_and_content_richness metrics.png" alt="Knowledge Base Comparison">
                                <div class="image-caption">Text readability and content richness metrics across different knowledge bases</div>
                            </div>
                            <div class="image-item-no-circle">
                                <img src="./images/fig8_structural_quality_metrics.png" alt="Retrieval Accuracy Results">
                                <div class="image-caption">Structural quality metrics across different knowledge bases</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Third Row -->
                <div class="experiment-grid-3">
                    <h3><i class="fas fa-search"></i> Retrieval Accuracy Results</h3>
                    <ul>
                        <li><span class="bold">~20 percentage points improvement</span> in <span class="bold">recall</span> and <span class="bold">precision</span></li>
                        <li><span class="bold">Claude Sonnet 4</span>: <span class="bold">58.04% recall</span> and <span class="bold">59.97% precision</span> GSB win rates</li>
                        <li>Qualitative cases: Traditional KB (<span class="bold">0% recall, 0% precision</span>) vs Q&A KB (<span class="bold">80% recall, 90% precision</span>)</li>
                    </ul>
                    <div class="media-container">
                        <div class="image-item-no-circle">
                            <img src="./images/fig9_retrieval_accuracy.png" alt="Text Quality Results">
                            <div class="image-caption">Retrieval accuracy metrics across different knowledge bases</div>
                        </div>
                        <div class="video-container">
                            <div class="video-preview" onclick="playVideo(this)">
                                <i class="fas fa-play"></i>
                            </div>
                            <div class="image-caption">Interactive Demo of knowledge retrieval and responses by chatbots that use two knowledge bases. On the left is a chatbot using the baseline knowledge base, while on the right is a chatbot using our Proposed Q&A knowledge base.</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="lang-content" id="zh-experiment">
                <h2 class="section-title">实验与分析</h2>
                
                <!-- First Row -->
                <div class="experiment-grid-1">
                    <div class="content-card">
                        <h3><i class="fas fa-file-alt"></i> 数据集</h3>
                        <ul>
                            <li><span class="bold">ELEC3442嵌入式系统</span>课程的<span class="bold">11个文档</span></li>
                            <li><span class="bold">286个基准查询</span>用于评估</li>
                            <li>跨<span class="bold">多种问题类型</span>的综合测试</li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-chart-bar"></i> 性能指标</h3>
                        <ul>
                            <li>跨<span class="bold">文本质量</span>和<span class="bold">检索指标</span>的综合评估</li>
                            <li>基于<span class="bold">LLM的评判</span>框架</li>
                            <li>在多种教育场景下的一致性改进</li>
                        </ul>
                    </div>
                </div>

                <!-- Second Row -->
                <div class="experiment-grid-2">
                    <div class="experiment-wide-card">
                        <h3><i class="fas fa-trophy"></i> 文本质量提升</h3>
                        <ul>
                            <li><span class="bold">Gemini 2.5 Pro</span>在<span class="bold">可读性方面</span>表现最佳</li>
                            <li><span class="bold">Claude Sonnet 4</span>和<span class="bold">DeepSeek R1</span>在<span class="bold">内容丰富度</span>方面领先</li>
                            <li><span class="bold">文本连贯性</span>和<span class="bold">技术深度</span>显著改善</li>
                        </ul>
                        <div class="image-row">
                            <div class="image-item-no-circle">
                                <img src="./images/fig7_text readability_and_content_richness metrics.png" alt="Knowledge Base Comparison">
                                <div class="image-caption">不同知识库的文本可读性和内容丰富度指标</div>
                            </div>
                            <div class="image-item-no-circle">
                                <img src="./images/fig8_structural_quality_metrics.png" alt="Retrieval Accuracy Results">
                                <div class="image-caption">不同知识库的结构质量指标</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Third Row -->
                <div class="experiment-grid-3">
                    <h3><i class="fas fa-search"></i> 检索精度结果</h3>
                    <ul>
                        <li><span class="bold">召回率</span>和<span class="bold">精确率</span>提升约<span class="bold">20个百分点</span></li>
                        <li><span class="bold">Claude Sonnet 4</span>：GSB胜率达<span class="bold">58.04%(召回率)</span>和<span class="bold">59.97%(精确率)</span></li>
                        <li>定性案例：传统知识库(<span class="bold">0%召回率，0%精确率</span>) vs 问答知识库(<span class="bold">80%召回率，90%精确率</span>)</li>
                    </ul>
                    <div class="media-container">
                        <div class="image-item-no-circle">
                            <img src="./images/fig9_retrieval_accuracy.png" alt="Text Quality Results">
                            <div class="image-caption">不同知识库的检索准确性指标</div>
                        </div>
                        <div class="video-container">
                            <div class="video-preview" onclick="playVideo(this)">
                                <i class="fas fa-play"></i>
                            </div>
                            <div class="image-caption">使用两个知识库的聊天机器人进行知识检索和回复的互动演示。左侧为使用基础知识库的聊天机器人，右侧为使用我们提出问答对知识库的聊天机器人</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contribution Section -->
    <section id="contribution" class="section">
        <div class="container">
            <div class="lang-content active" id="en-contribution">
                <h2 class="section-title">Contribution</h2>
                <div class="contribution-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-lightbulb"></i> Methodological Innovation</h3>
                        <p>Proposed a <span class="bold">data-centric, model-agnostic</span> knowledge base construction workflow that enhances <span class="bold">knowledge quality</span> through preprocessing stages, reducing dependence on expensive <span class="bold">fine-tuning</span> or <span class="bold">ultra-long context inference</span>.</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-microscope"></i> Empirical Validation</h3>
                        <p>Provided empirical evidence through <span class="bold">large-scale metrics</span> and concrete case studies that <span class="bold">synthetic multi-LLM Q&A corpora</span> significantly improve <span class="bold">RAG accuracy</span> and <span class="bold">answer utility</span> in higher education settings.</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-tools"></i> Evaluation Framework</h3>
                        <p>Established an integrated assessment framework with <span class="bold">LLM-as-judge metrics</span>, portable to other courses and domains, enabling <span class="bold">continuous improvement</span> of educational chatbots.</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-rocket"></i> Practical Value</h3>
                        <p>Demonstrated that <span class="bold">rigorous knowledge engineering</span> approaches offer a <span class="bold">pragmatic and scalable path</span> to trustworthy <span class="bold">GenAI assistance</span> in knowledge-intensive academic environments.</p>
                    </div>
                </div>
            </div>
            <div class="lang-content" id="zh-contribution">
                <h2 class="section-title">主要贡献</h2>
                <div class="contribution-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-lightbulb"></i> 方法论创新</h3>
                        <p>提出了<span class="bold">数据中心化、模型无关</span>的知识库构建工作流程，通过预处理阶段提升<span class="bold">知识质量</span>，减少对昂贵<span class="bold">微调</span>或<span class="bold">超长上下文推理</span>的依赖。</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-microscope"></i> 实证验证</h3>
                        <p>通过<span class="bold">大规模指标</span>和具体案例研究，实证证明了<span class="bold">合成多模型问答语料库</span>在高等教育场景下显著提升<span class="bold">RAG精度</span>和<span class="bold">答案实用性</span>。</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-tools"></i> 评估框架</h3>
                        <p>建立了包含<span class="bold">LLM评判指标</span>的集成评估框架，可移植到其他课程和领域，支持教育聊天机器人的<span class="bold">持续改进</span>。</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-rocket"></i> 实用价值</h3>
                        <p>验证了<span class="bold">严格的知识工程</span>方法为知识密集型学术环境中的可信<span class="bold">GenAI辅助</span>提供了<span class="bold">实用且可扩展的路径</span>。</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Multi-LLM Knowledge Enhancement Research. All rights reserved.</p>
            <p>Contact: zhangnianheng2002@foxmail.com | Department of EEE, the University of Hong Kong</p>
        </div>
    </footer>

  <script>
    let currentLang = 'en';

    /**
     * Ensures the first methodology tab & image of the currently‑visible language
     * block are activated so that an image is always shown after a language toggle.
     */
    function setDefaultMethodologyTab(lang) {
      const wrapper = document.querySelector(`#${lang}-methodology .methodology-content`);
      if (!wrapper) return;
      // Remove any lingering active classes inside this language block
      wrapper.querySelectorAll('.methodology-tab').forEach(t => t.classList.remove('active'));
      wrapper.querySelectorAll('.methodology-image').forEach(img => img.classList.remove('active'));
      // Activate the first tab + corresponding image
      const firstTab = wrapper.querySelector('.methodology-tab[data-tab="1"]');
      const firstImg = wrapper.querySelector('.methodology-image[data-image="1"]');
      if (firstTab && firstImg) {
        firstTab.classList.add('active');
        firstImg.classList.add('active');
      }
    }

    // Language toggle — now also resets the default tab/image for the chosen lang
    function toggleLanguage() {
        const langText = document.getElementById('langText');
        const logoText = document.getElementById('logoText');
        const enEls = document.querySelectorAll('[id^="en-"]');
        const zhEls = document.querySelectorAll('[id^="zh-"]');
        const navLinks = document.querySelectorAll('.nav-links a');
        
        if (currentLang === 'en') {
            currentLang = 'zh';
            langText.textContent = 'English';
            logoText.textContent = logoText.parentElement.getAttribute('data-zh');
            navLinks.forEach(link => {
                link.textContent = link.getAttribute('data-zh');
            });
            enEls.forEach(el => el.classList.remove('active'));
            zhEls.forEach(el => el.classList.add('active'));
        } else {
            currentLang = 'en';
            langText.textContent = '中文';
            logoText.textContent = logoText.parentElement.getAttribute('data-en');
            navLinks.forEach(link => {
                link.textContent = link.getAttribute('data-en');
            });
            zhEls.forEach(el => el.classList.remove('active'));
            enEls.forEach(el => el.classList.add('active'));
        }
        setDefaultMethodologyTab(currentLang);
    }

    /**
     * TAB SWITCHING (scoped per‑language)
     * Limiting the query scope to the current .methodology-content element prevents
     * English tabs from toggling Chinese images (and vice‑versa).
     */
    document.querySelectorAll('.methodology-tab').forEach(tab => {
      tab.addEventListener('click', function () {
        const tabNumber = this.dataset.tab;
        const wrapper = this.closest('.methodology-content');
        if (!wrapper) return;
        // Clear active states only within the current language block
        wrapper.querySelectorAll('.methodology-tab').forEach(t => t.classList.remove('active'));
        wrapper.querySelectorAll('.methodology-image').forEach(img => img.classList.remove('active'));
        // Activate the current tab + the corresponding image
        this.classList.add('active');
        const targetImg = wrapper.querySelector(`.methodology-image[data-image="${tabNumber}"]`);
        if (targetImg) targetImg.classList.add('active');
      });
    });

    // Video player (unchanged)
    function playVideo(element) {
      const videoContainer = element.parentNode;
      const videoHTML = `\n        <video class="video-player" controls autoplay>\n          <source src="./videos/demo_video.mp4" type="video/mp4">\n          <source src="./videos/demo_video.webm" type="video/webm">\n          Your browser does not support the video tag.\n        </video>`;
      const caption = currentLang === 'en'
        ? 'Interactive Demo of knowledge retrieval and responses by chatbots that use two knowledge bases. On the left is a chatbot using the baseline knowledge base, while on the right is a chatbot using our Proposed Q&A knowledge base.'
        : '使用两个知识库的聊天机器人进行知识检索和回复的互动演示。左侧为使用基础知识库的聊天机器人，右侧为使用我们提出问答对知识库的聊天机器人';
      videoContainer.innerHTML = videoHTML + `<div class="image-caption">${caption}</div>`;
    }

    // Smooth scrolling (unchanged)
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        const headerHeight = document.querySelector('.header').offsetHeight;
        const targetPos = target.offsetTop - headerHeight;
        window.scrollTo({ top: targetPos, behavior: 'smooth' });
      });
    });

    // Intersection Observer (unchanged)
    const observerOptions = { threshold: 0.1, rootMargin: '0px 0px -50px 0px' };
    const observer = new IntersectionObserver(entries => {
      entries.forEach(entry => {
        if (entry.isIntersecting) entry.target.classList.add('visible');
      });
    }, observerOptions);
    document.querySelectorAll('.section').forEach(section => observer.observe(section));

    // Initialize default tab for English on first load
    document.addEventListener('DOMContentLoaded', () => setDefaultMethodologyTab('en'));

    function setupImageZoom() {
        const images = document.querySelectorAll('img:not(.modal-content)');
        const modal = document.getElementById('imageModal');
        const modalImg = document.getElementById('modalImage');
        const closeBtn = document.querySelector('.close-modal');

        images.forEach(img => {
            if (img.parentElement.className !== 'video-preview') {
                img.style.cursor = 'zoom-in';
                img.addEventListener('click', (e) => {
                    e.stopPropagation();
                    modal.style.display = 'block';
                    modalImg.src = img.src;
                });
            }
        });

        closeBtn.addEventListener('click', () => {
            modal.style.display = 'none';
        });

        modal.addEventListener('click', (e) => {
            if (e.target === modal) {
                modal.style.display = 'none';
            }
        });

        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && modal.style.display === 'block') {
                modal.style.display = 'none';
            }
        });
    }

    // 在 DOMContentLoaded 事件中初始化
    document.addEventListener('DOMContentLoaded', () => {
        // ...existing code...
        setupImageZoom();
    });
  </script>
  <!-- ↑↑↑  END REPLACED SCRIPT BLOCK  ↑↑↑ -->

  <div id="imageModal" class="image-modal">
    <span class="close-modal">&times;</span>
    <img class="modal-content" id="modalImage">
  </div>
</body>
</html>
