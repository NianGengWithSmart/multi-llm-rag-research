<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-LLM Knowledge Distillation and RAG System Optimization</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            overflow-x: hidden;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        .header {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            box-shadow: 0 2px 20px rgba(0,0,0,0.1);
        }

        .nav {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 2rem;
        }

        .logo {
            font-size: 1.5rem;
            font-weight: bold;
            color: #667eea;
        }

        .nav-links {
            display: flex;
            list-style: none;
            gap: 2rem;
        }

        .nav-links a {
            text-decoration: none;
            color: #333;
            font-weight: 500;
            transition: color 0.3s;
        }

        .nav-links a:hover {
            color: #667eea;
        }

        .lang-switch {
            background: #667eea;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s;
        }

        .lang-switch:hover {
            background: #5a6fd8;
            transform: translateY(-2px);
        }

        /* Hero Section */
        .hero {
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: center;
            color: white;
            position: relative;
        }

        .hero-content h1 {
            font-size: 3.5rem;
            margin-bottom: 1rem;
            animation: fadeInUp 1s ease-out;
        }

        .hero-content p {
            font-size: 1.2rem;
            margin-bottom: 2rem;
            animation: fadeInUp 1s ease-out 0.3s both;
        }

        .cta-button {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: 2px solid white;
            padding: 1rem 2rem;
            border-radius: 50px;
            text-decoration: none;
            font-weight: bold;
            transition: all 0.3s;
            animation: fadeInUp 1s ease-out 0.6s both;
        }

        .cta-button:hover {
            background: white;
            color: #667eea;
            transform: translateY(-3px);
        }

        /* Sections */
        .section {
            padding: 5rem 0;
            opacity: 0;
            transform: translateY(50px);
            transition: all 0.6s;
        }

        .section.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .section:nth-child(even) {
            background: rgba(255, 255, 255, 0.9);
        }

        .section:nth-child(odd) {
            background: rgba(255, 255, 255, 0.95);
        }

        .section-title {
            font-size: 2.5rem;
            text-align: center;
            margin-bottom: 3rem;
            color: #667eea;
        }

        /* Bold text styling */
        .bold {
            font-weight: bold;
            color: #5a6fd8;
        }

        .bold_white {
            font-weight: bold;
            color: white;
        }

        .content-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-bottom: 2rem;
        }

        .content-card {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: all 0.3s;
        }

        .content-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0,0,0,0.15);
        }

        .content-card h3 {
            color: #667eea;
            margin-bottom: 1rem;
            font-size: 1.3rem;
        }

        .content-card ul {
            padding-left: 1.5rem;
        }

        .content-card li {
            margin-bottom: 0.5rem;
        }

        /* Images */
        .image-container {
            text-align: center;
            margin: 2rem 0;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .image-caption {
            margin-top: 1rem;
            font-style: italic;
            color: #666;
            font-size: 0.9rem;
            text-align: center;
        }

        /* Wide image for system architecture */
        .wide-image-container {
            text-align: center;
            margin: 3rem 0;
        }

        .wide-image-container img {
            max-width: 100%;
            width: 90%;
            height: auto;
            border-radius: 15px;
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        .image-row {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 2rem;
            margin-top: 2rem;
            justify-items: center;
        }

        .image-item {
            text-align: center;
            max-width: 400px;
        }

        .image-item img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            aspect-ratio: auto;
            object-fit: contain;
        }

        .image-item-no-circle {
            text-align: center;
        }

        .image-item-no-circle img {
            max-width: 100%;
            height: auto;
            border-radius: 0px;
            aspect-ratio: auto;
            object-fit: contain;
        }

        /* Methodology specific styles */
        .methodology-intro {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 3rem;
            text-align: center;
            font-size: 1.2rem;
        }

        .methodology-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 3rem;
            align-items: start;
        }

        .methodology-tabs {
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .methodology-tab {
            background: white;
            padding: 1.5rem;
            border-radius: 15px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            cursor: pointer;
            transition: all 0.3s;
            border-left: 4px solid transparent;
        }

        .methodology-tab:hover {
            transform: translateX(5px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.15);
        }

        .methodology-tab.active {
            border-left-color: #667eea;
            background: linear-gradient(135deg, #f8f9ff, #ffffff);
            transform: translateX(10px);
        }

        .methodology-tab h3 {
            color: #667eea;
            margin-bottom: 0.5rem;
            font-size: 1.2rem;
        }

        .methodology-visual {
            position: sticky;
            top: 120px;
            text-align: center;
        }

        .methodology-image {
            opacity: 0;
            transform: translateY(20px);
            transition: all 0.5s;
            display: none;
        }

        .methodology-image.active {
            opacity: 1;
            transform: translateY(0);
            display: block;
        }

        .methodology-image img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        /* Experiment section styles */
        .experiment-grid-1 {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-bottom: 3rem;
        }

        .experiment-grid-2 {
            margin-bottom: 3rem;
        }

        .experiment-wide-card {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: all 0.3s;
            grid-column: 1 / -1;
        }

        .experiment-wide-card h3 {
            color: #667eea;
            margin-bottom: 1.5rem;
            font-size: 1.3rem;
        }

        .experiment-wide-card ul {
            padding-left: 1.5rem;
            margin-bottom: 2rem;
        }

        .experiment-wide-card li {
            margin-bottom: 0.5rem;
        }

        .experiment-grid-3 {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
        }

        .experiment-grid-3 h3 {
            color: #667eea;
            margin-bottom: 1.5rem;
            font-size: 1.3rem;
        }

        .experiment-grid-3 ul {
            padding-left: 1.5rem;
            margin-bottom: 2rem;
        }

        .experiment-grid-3 li {
            margin-bottom: 0.5rem;
        }

        .media-container {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            margin-top: 2rem;
        }

        .video-container {
            position: relative;
            text-align: center;
        }

        .video-player {
            width: 100%;
            max-width: 100%;
            border-radius: 10px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }

        .video-preview {
            width: 100%;
            height: 200px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: all 0.3s;
        }

        .video-preview:hover {
            transform: scale(1.02);
        }

        /* Contribution section styles */
        .contribution-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 2rem;
        }

        /* Language Toggle */
        .lang-content {
            display: none;
        }

        .lang-content.active {
            display: block;
        }

        /* Animations */
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(50px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Responsive */
        @media (max-width: 768px) {
            .nav {
                flex-direction: column;
                gap: 1rem;
            }

            .nav-links {
                flex-direction: column;
                text-align: center;
                gap: 1rem;
            }

            .hero-content h1 {
                font-size: 2.5rem;
            }

            .section-title {
                font-size: 2rem;
            }

            .content-grid {
                grid-template-columns: 1fr;
            }

            .methodology-content {
                grid-template-columns: 1fr;
                gap: 2rem;
            }

            .methodology-visual {
                position: static;
            }

            .experiment-grid-1 {
                grid-template-columns: 1fr;
            }

            .media-container {
                grid-template-columns: 1fr;
            }

            .contribution-grid {
                grid-template-columns: 1fr;
            }

            .image-row {
                grid-template-columns: 1fr;
            }

            .wide-image-container img {
                width: 95%;
            }
        }

        /* Footer */
        .footer {
            background: #333;
            color: white;
            text-align: center;
            padding: 2rem;
        }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <nav class="nav container">
            <div class="logo">
                <i class="fas fa-brain"></i> Multi-LLM RAG Research
            </div>
            <ul class="nav-links">
                <li><a href="#background">Background</a></li>
                <li><a href="#methodology">Methodology</a></li>
                <li><a href="#experiment">Experiment</a></li>
                <li><a href="#contribution">Contribution</a></li>
            </ul>
            <button class="lang-switch" onclick="toggleLanguage()">
                <i class="fas fa-language"></i> <span id="langText">中文</span>
            </button>
        </nav>
    </header>

    
    <!-- Hero Section -->
    <section class="hero">
        <div class="hero-content">
            <div class="lang-content active" id="en-hero">
                <h1>Multi-LLM Knowledge Distillation and RAG System Optimization</h1>
                <p>For Educational Applications</p>
            </div>
            <div class="lang-content" id="zh-hero">
                <h1>面向教育场景的多模型知识蒸馏与RAG系统优化研究</h1>
                <p>提升检索增强生成系统在高等教育中的应用效果</p>
            </div>
            <a href="#background" class="cta-button">
                <i class="fas fa-arrow-down"></i> Explore Research
            </a>
        </div>
    </section>

    <!-- Background Section -->
    <section id="background" class="section">
        <div class="container">
            <div class="lang-content active" id="en-background">
                <!-- System Architecture Comparison -->
                <div class="wide-image-container">
                    <img src="./images/fig0_system_architecture_comparison.png" alt="System Architecture Comparison">
                    <div class="image-caption">Comparison of the system architecture diagrams of a traditional Retrieval Augmentation Generation (RAG) system and a RAG Chatbot System Based On Multiple Model Synthetic Q&A Generation Comparison and Integration. Prior to inference, knowledge is extracted and augmented based on course document content using Multiple LLMs and a high quality Q&A set is generated for downstream retrieval.</div>
                </div>

                <h2 class="section-title">Background & Objective</h2>
                <div class="content-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-exclamation-triangle"></i> Current Challenges</h3>
                        <ul>
                            <li>Traditional <span class="bold">RAG systems</span> suffer from <span class="bold">heterogeneous document formats</span> and <span class="bold">noise interference</span></li>
                            <li><span class="bold">Improper segmentation strategies</span> lead to <span class="bold">low retrieval accuracy</span></li>
                            <li>Severe <span class="bold">hallucination problems</span> in course-specific knowledge scenarios</li>
                            <li>Limited effectiveness when handling <span class="bold">proprietary educational content</span></li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-target"></i> Research Objectives</h3>
                        <ul>
                            <li>Construct <span class="bold">high-quality course-specific knowledge bases</span></li>
                            <li>Generate <span class="bold">structured Q&A knowledge bases</span> through <span class="bold">multi-model collaborative knowledge distillation</span></li>
                            <li>Enhance <span class="bold">RAG system retrieval accuracy</span> for educational applications</li>
                            <li>Validate <span class="bold">methodology effectiveness</span> in real educational scenarios</li>
                        </ul>
                    </div>
                </div>
                
                <!-- 
                =================== 图片路径替换说明 ===================
                以下图片路径需要根据部署环境进行替换：
                
                1. 本地开发环境：
                   - 创建 ./images/ 文件夹
                   - 将图片放入该文件夹
                   - 使用相对路径：./images/fig1_traditional_rag_problems.jpg
                
                2. GitHub Pages部署：
                   - 将图片上传到仓库的 images/ 文件夹
                   - 使用相对路径：./images/fig1_traditional_rag_problems.jpg
                   - 或使用GitHub raw链接：https://raw.githubusercontent.com/your-username/repo-name/main/images/fig1_traditional_rag_problems.jpg
                
                3. Netlify/Vercel等云端部署：
                   - 将图片放在项目的 public/images/ 或 images/ 文件夹
                   - 使用相对路径：./images/fig1_traditional_rag_problems.jpg
                
                4. 使用CDN或云存储：
                   - 上传到阿里云OSS、AWS S3、腾讯云COS等
                   - 使用完整URL：https://your-bucket.oss-region.aliyuncs.com/images/fig1_traditional_rag_problems.jpg
                
                建议的图片命名规范：
                - fig1_traditional_rag_problems.jpg/png
                - fig2_llm_hallucination_examples.jpg/png
                - fig3_methodology_generation.jpg/png
                - fig4_evaluation_framework.jpg/png
                - fig5_voting_mechanism.jpg/png
                - fig6_kb_optimization.jpg/png
                - fig7_performance_comparison.jpg/png
                - fig8_retrieval_accuracy.jpg/png
                - fig9_text_quality_results.jpg/png
                - demo_video.mp4
                =================== 图片路径替换说明结束 ===================
                -->

                <div class="image-row">
                    <div class="image-item">
                        <img src="./images/fig1_llm_hallucination_examples.png" alt="LLM Hallucination Examples">
                        <div class="image-caption">Examples of LLM lacking critical knowledge in Course-specific Queries. When a student asked about ELEC3442 project requirements, LLM gaves generic hardware design steps, not the course-specific details. </div>
                    </div>
                    <div class="image-item">
                        <img src="./images/fig2_traditional_rag_problems.png" alt="Traditional RAG Problems">
                        <div class="image-caption">Challenges of traditional RAG systems in the knowledge base building process</div>
                    </div>
                </div>
            </div>
            <div class="lang-content" id="zh-background">
                <!-- System Architecture Comparison -->
                <div class="wide-image-container">
                    <img src="./images/system_architecture_comparison.png" alt="System Architecture Comparison">
                    <div class="image-caption">传统检索增强生成（RAG）系统与基于多模型合成问答生成比较集成的RAG聊天机器人系统的系统架构图比较。在推理之前，使用多个LLM基于课程文档内容提取和增强知识，并生成高质量的问答集用于下游检索。</div>
                </div>

                <h2 class="section-title">研究背景与目标</h2>
                <div class="content-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-exclamation-triangle"></i> 现有挑战</h3>
                        <ul>
                            <li>传统<span class="bold">RAG系统</span>存在<span class="bold">文档格式异构</span>、<span class="bold">噪声干扰</span>等问题</li>
                            <li><span class="bold">分割策略不当</span>导致<span class="bold">检索精度低下</span></li>
                            <li>在课程专有知识场景中<span class="bold">幻觉问题严重</span></li>
                            <li>处理<span class="bold">教育专有内容</span>时效果有限</li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-target"></i> 研究目标</h3>
                        <ul>
                            <li>构建<span class="bold">高质量的课程专用知识库</span></li>
                            <li>通过<span class="bold">多模型协同知识蒸馏</span>生成<span class="bold">结构化问答知识库</span></li>
                            <li>提升<span class="bold">RAG系统在教育应用中的检索准确性</span></li>
                            <li>验证方法在实际教育场景中的<span class="bold">有效性</span></li>
                        </ul>
                    </div>
                </div>
                <div class="image-row">
                    <div class="image-item">
                        <img src="./images/fig1_llm_hallucination_examples.png" alt="LLM Hallucination Examples">
                        <div class="image-caption">LLM 在特定课程问题中缺乏关键知识的示例。当一名学生询问 ELEC3442 项目要求时，LLM 只提供了一般的硬件设计步骤，而没有提供特定课程的详细信息。</div>
                    </div>
                    <div class="image-item">
                        <img src="./images/fig2_traditional_rag_problems.png" alt="Traditional RAG Problems">
                        <div class="image-caption">传统RAG系统在知识库构建过程中的挑战</div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Methodology Section -->
    <section id="methodology" class="section">
        <div class="container">
            <div class="lang-content active" id="en-methodology">
                <h2 class="section-title">Methodology</h2>
                <div class="methodology-intro">
                    This research proposes an innovative <span class="bold_white">"Multi-LLM Synthetic Q&A Generation, Comparison, and Integration"</span> pipeline with a core workflow of <span class="bold_white">"generate → evaluate → compare → integrate"</span>.
                </div>
                <div class="methodology-content">
                    <div class="methodology-tabs">
                        <div class="methodology-tab active" data-tab="1">
                            <h3><i class="fas fa-cogs"></i> Multi-Model Collaborative Generation</h3>
                            <p>Utilizes five frontier LLMs (<span class="bold">Claude Sonnet 4</span>, <span class="bold">Gemini 2.5 Pro</span>, <span class="bold">DeepSeek R1</span>, <span class="bold">ChatGPT o3</span>, <span class="bold">Grok 4</span>) with <span class="bold">Chain-of-Thought prompts</span> to extract meta-knowledge and generate self-contained Q&A pairs.</p>
                        </div>
                        <div class="methodology-tab" data-tab="2">
                            <h3><i class="fas fa-chart-line"></i> Quantitative Evaluation Framework</h3>
                            <p>Designs comprehensive assessment system encompassing <span class="bold">text quality metrics</span> (readability, coherence, technical term density) and <span class="bold">retrieval accuracy metrics</span> (recall, precision). Through comprehensive evaluation, we select a high-quality Q&A knowledge base produced through <span class="bold">knowledge distillation</span> as the foundation for subsequent integration.</p>
                        </div>
                        <div class="methodology-tab" data-tab="3">
                            <h3><i class="fas fa-vote-yea"></i> Cross-Model Voting Mechanism</h3>
                            <p>Employs <span class="bold">semantic similarity comparison</span> and <span class="bold">voting mechanisms</span> to filter and integrate complementary Q&A pairs from different models. High-quality Q&A pairs selected through voting mechanisms must have <span class="bold">semantic similarity < 10%</span> with existing Q&A knowledge base to ensure diversity and prevent redundancy.</p>
                        </div>
                        <div class="methodology-tab" data-tab="4">
                            <h3><i class="fas fa-database"></i> Knowledge Base Optimization</h3>
                            <p>Applies <span class="bold">rule-based segmentation strategies</span> for generated structured Q&A pairs, replacing traditional <span class="bold">automatic segmentation methods</span> to achieve optimal knowledge base construction.</p>
                        </div>
                    </div>
                    <div class="methodology-visual">
                        <div class="methodology-image active" data-image="1">
                            <img src="./images/fig3_methodology.png" alt="Multi-Model Generation">
                            <div class="image-caption">Multi-LLM Collaborative Q&A Generation Process</div>
                        </div>
                        <div class="methodology-image" data-image="2">
                            <img src="./images/fig4_evaluation_framework.png" alt="Evaluation Framework">
                            <div class="image-caption">Comprehensive Quantitative Evaluation Framework</div>
                        </div>
                        <div class="methodology-image" data-image="3">
                            <img src="./images/fig5_voting_mechanism.png" alt="Voting Mechanism">
                            <div class="image-caption">Cross-Model Voting and Integration Mechanism</div>
                        </div>
                        <div class="methodology-image" data-image="4">
                            <img src="./images/fig6_kb_optimization.png" alt="Knowledge Base Optimization">
                            <div class="image-caption">Rule-based Knowledge Base Optimization Strategy</div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="lang-content" id="zh-methodology">
                <h2 class="section-title">研究方法</h2>
                <div class="methodology-intro">
                    本研究提出了创新的<span class="bold_white">"多模型合成问答生成、比较与集成"</span>管道，核心流程为<span class="bold_white">"生成→评估→比较→集成"</span>。
                </div>
                <div class="methodology-content">
                    <div class="methodology-tabs">
                        <div class="methodology-tab active" data-tab="1">
                            <h3><i class="fas fa-cogs"></i> 多模型协同生成</h3>
                            <p>采用五个前沿LLM（<span class="bold">Claude Sonnet 4</span>、<span class="bold">Gemini 2.5 Pro</span>、<span class="bold">DeepSeek R1</span>、<span class="bold">ChatGPT o3</span>、<span class="bold">Grok 4</span>），使用<span class="bold">链式思维提示词</span>提取元知识并生成自包含问答对。</p>
                        </div>
                        <div class="methodology-tab" data-tab="2">
                            <h3><i class="fas fa-chart-line"></i> 量化评估框架</h3>
                            <p>设计综合评估系统，涵盖<span class="bold">文本质量指标</span>（可读性、连贯性、技术术语密度等）和<span class="bold">检索准确性指标</span>（召回率、精确率）。通过综合评估，选出一个通过<span class="bold">知识蒸馏</span>产出的高质量Q&A知识集作为后续集成的基础。</p>
                        </div>
                        <div class="methodology-tab" data-tab="3">
                            <h3><i class="fas fa-vote-yea"></i> 跨模型投票机制</h3>
                            <p>采用<span class="bold">语义相似度比较</span>和<span class="bold">投票机制</span>，筛选并整合来自不同模型的互补性问答对。通过投票机制选出的高质量Q&A需要与现有Q&A知识集的<span class="bold">语义相似度<10%</span>，以确保多样性和避免冗余。</p>
                        </div>
                        <div class="methodology-tab" data-tab="4">
                            <h3><i class="fas fa-database"></i> 知识库优化</h3>
                            <p>对生成的结构化问答对采用<span class="bold">基于规则的分割策略</span>，替代传统<span class="bold">自动分割方法</span>，实现最优的知识库构建。</p>
                        </div>
                    </div>
                    <div class="methodology-visual">
                        <div class="methodology-image active" data-image="1">
                            <img src="./images/fig3_methodology.png" alt="Multi-Model Generation">
                            <div class="image-caption">多模型协同问答生成流程</div>
                        </div>
                        <div class="methodology-image" data-image="2">
                            <img src="./images/fig4_evaluation_framework.png" alt="Evaluation Framework">
                            <div class="image-caption">综合量化评估框架</div>
                        </div>
                        <div class="methodology-image" data-image="3">
                            <img src="./images/fig5_voting_mechanism.png" alt="Voting Mechanism">
                            <div class="image-caption">跨模型投票与集成机制</div>
                        </div>
                        <div class="methodology-image" data-image="4">
                            <img src="./images/fig6_kb_optimization.png" alt="Knowledge Base Optimization">
                            <div class="image-caption">基于规则的知识库优化策略</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Experiment Section -->
    <section id="experiment" class="section">
        <div class="container">
            <div class="lang-content active" id="en-experiment">
                <h2 class="section-title">Experiment & Analysis</h2>
                
                <!-- First Row -->
                <div class="experiment-grid-1">
                    <div class="content-card">
                        <h3><i class="fas fa-file-alt"></i> Dataset</h3>
                        <ul>
                            <li><span class="bold">11 documents</span> from <span class="bold">ELEC3442 Embedded System</span> course</li>
                            <li><span class="bold">286 benchmark queries</span> for evaluation</li>
                            <li>Comprehensive testing across <span class="bold">diverse question types</span></li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-chart-bar"></i> Performance Metrics</h3>
                        <ul>
                            <li>Comprehensive evaluation across <span class="bold">text quality</span> and <span class="bold">retrieval metrics</span></li>
                            <li><span class="bold">LLM-as-Judge</span> evaluation framework</li>
                            <li>Consistent improvements across diverse educational scenarios</li>
                        </ul>
                    </div>
                </div>

                <!-- Second Row -->
                <div class="experiment-grid-2">
                    <div class="experiment-wide-card">
                        <h3><i class="fas fa-trophy"></i> Text Quality Enhancement</h3>
                        <ul>
                            <li><span class="bold">Gemini 2.5 Pro</span> achieved optimal <span class="bold">readability performance</span></li>
                            <li><span class="bold">Claude Sonnet 4</span> and <span class="bold">DeepSeek R1</span> led in <span class="bold">content richness</span></li>
                            <li>Significant improvements in <span class="bold">text coherence</span> and <span class="bold">technical depth</span></li>
                        </ul>
                        <div class="image-row">
                            <div class="image-item-no-circle">
                                <img src="./images/fig7_text readability_and_content_richness metrics.png" alt="Knowledge Base Comparison">
                                <div class="image-caption">Text readability and content richness metrics across different knowledge bases</div>
                            </div>
                            <div class="image-item-no-circle">
                                <img src="./images/fig8_structural_quality_metrics.png" alt="Retrieval Accuracy Results">
                                <div class="image-caption">Structural quality metrics across different knowledge bases</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Third Row -->
                <div class="experiment-grid-3">
                    <h3><i class="fas fa-search"></i> Retrieval Accuracy Results</h3>
                    <ul>
                        <li><span class="bold">~20 percentage points improvement</span> in <span class="bold">recall</span> and <span class="bold">precision</span></li>
                        <li><span class="bold">Claude Sonnet 4</span>: <span class="bold">58.04% recall</span> and <span class="bold">59.97% precision</span> GSB win rates</li>
                        <li>Qualitative cases: Traditional KB (<span class="bold">0% recall, 0% precision</span>) vs Q&A KB (<span class="bold">80% recall, 90% precision</span>)</li>
                    </ul>
                    <div class="media-container">
                        <div class="image-item-no-circle">
                            <img src="./images/fig9_retrieval_accuracy.png" alt="Text Quality Results">
                            <div class="image-caption">Retrieval accuracy metrics across different knowledge bases</div>
                        </div>
                        <div class="video-container">
                            <div class="video-preview" onclick="playVideo(this)">
                                <i class="fas fa-play"></i>
                            </div>
                            <div class="image-caption">Interactive Demo of knowledge retrieval and responses by chatbots that use two knowledge bases. On the left is a chatbot using the baseline knowledge base, while on the right is a chatbot using our Proposed Q&A knowledge base.</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="lang-content" id="zh-experiment">
                <h2 class="section-title">实验与分析</h2>
                
                <!-- First Row -->
                <div class="experiment-grid-1">
                    <div class="content-card">
                        <h3><i class="fas fa-file-alt"></i> 数据集</h3>
                        <ul>
                            <li><span class="bold">ELEC3442嵌入式系统</span>课程的<span class="bold">11个文档</span></li>
                            <li><span class="bold">286个基准查询</span>用于评估</li>
                            <li>跨<span class="bold">多种问题类型</span>的综合测试</li>
                        </ul>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-chart-bar"></i> 性能指标</h3>
                        <ul>
                            <li>跨<span class="bold">文本质量</span>和<span class="bold">检索指标</span>的综合评估</li>
                            <li>基于<span class="bold">LLM的评判</span>框架</li>
                            <li>在多种教育场景下的一致性改进</li>
                        </ul>
                    </div>
                </div>

                <!-- Second Row -->
                <div class="experiment-grid-2">
                    <div class="experiment-wide-card">
                        <h3><i class="fas fa-trophy"></i> 文本质量提升</h3>
                        <ul>
                            <li><span class="bold">Gemini 2.5 Pro</span>在<span class="bold">可读性方面</span>表现最佳</li>
                            <li><span class="bold">Claude Sonnet 4</span>和<span class="bold">DeepSeek R1</span>在<span class="bold">内容丰富度</span>方面领先</li>
                            <li><span class="bold">文本连贯性</span>和<span class="bold">技术深度</span>显著改善</li>
                        </ul>
                        <div class="image-row">
                            <div class="image-item-no-circle">
                                <img src="./images/fig7_text readability_and_content_richness metrics.png" alt="Knowledge Base Comparison">
                                <div class="image-caption">不同知识库的文本可读性和内容丰富度指标</div>
                            </div>
                            <div class="image-item-no-circle">
                                <img src="./images/fig8_structural_quality_metrics.png" alt="Retrieval Accuracy Results">
                                <div class="image-caption">不同知识库的结构质量指标</div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Third Row -->
                <div class="experiment-grid-3">
                    <h3><i class="fas fa-search"></i> 检索精度结果</h3>
                    <ul>
                        <li><span class="bold">召回率</span>和<span class="bold">精确率</span>提升约<span class="bold">20个百分点</span></li>
                        <li><span class="bold">Claude Sonnet 4</span>：GSB胜率达<span class="bold">58.04%(召回率)</span>和<span class="bold">59.97%(精确率)</span></li>
                        <li>定性案例：传统知识库(<span class="bold">0%召回率，0%精确率</span>) vs 问答知识库(<span class="bold">80%召回率，90%精确率</span>)</li>
                    </ul>
                    <div class="media-container">
                        <div class="image-item-no-circle">
                            <img src="./images/fig9_retrieval_accuracy.png" alt="Text Quality Results">
                            <div class="image-caption">不同知识库的检索准确性指标</div>
                        </div>
                        <div class="video-container">
                            <div class="video-preview" onclick="playVideo(this)">
                                <i class="fas fa-play"></i>
                            </div>
                            <div class="image-caption">使用两个知识库的聊天机器人进行知识检索和回复的互动演示。左侧为使用基础知识库的聊天机器人，右侧为使用我们提出问答对知识库的聊天机器人</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contribution Section -->
    <section id="contribution" class="section">
        <div class="container">
            <div class="lang-content active" id="en-contribution">
                <h2 class="section-title">Contribution</h2>
                <div class="contribution-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-lightbulb"></i> Methodological Innovation</h3>
                        <p>Proposed a <span class="bold">data-centric, model-agnostic</span> knowledge base construction workflow that enhances <span class="bold">knowledge quality</span> through preprocessing stages, reducing dependence on expensive <span class="bold">fine-tuning</span> or <span class="bold">ultra-long context inference</span>.</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-microscope"></i> Empirical Validation</h3>
                        <p>Provided empirical evidence through <span class="bold">large-scale metrics</span> and concrete case studies that <span class="bold">synthetic multi-LLM Q&A corpora</span> significantly improve <span class="bold">RAG accuracy</span> and <span class="bold">answer utility</span> in higher education settings.</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-tools"></i> Evaluation Framework</h3>
                        <p>Established an integrated assessment framework with <span class="bold">LLM-as-judge metrics</span>, portable to other courses and domains, enabling <span class="bold">continuous improvement</span> of educational chatbots.</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-rocket"></i> Practical Value</h3>
                        <p>Demonstrated that <span class="bold">rigorous knowledge engineering</span> approaches offer a <span class="bold">pragmatic and scalable path</span> to trustworthy <span class="bold">GenAI assistance</span> in knowledge-intensive academic environments.</p>
                    </div>
                </div>
            </div>
            <div class="lang-content" id="zh-contribution">
                <h2 class="section-title">主要贡献</h2>
                <div class="contribution-grid">
                    <div class="content-card">
                        <h3><i class="fas fa-lightbulb"></i> 方法论创新</h3>
                        <p>提出了<span class="bold">数据中心化、模型无关</span>的知识库构建工作流程，通过预处理阶段提升<span class="bold">知识质量</span>，减少对昂贵<span class="bold">微调</span>或<span class="bold">超长上下文推理</span>的依赖。</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-microscope"></i> 实证验证</h3>
                        <p>通过<span class="bold">大规模指标</span>和具体案例研究，实证证明了<span class="bold">合成多模型问答语料库</span>在高等教育场景下显著提升<span class="bold">RAG精度</span>和<span class="bold">答案实用性</span>。</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-tools"></i> 评估框架</h3>
                        <p>建立了包含<span class="bold">LLM评判指标</span>的集成评估框架，可移植到其他课程和领域，支持教育聊天机器人的<span class="bold">持续改进</span>。</p>
                    </div>
                    <div class="content-card">
                        <h3><i class="fas fa-rocket"></i> 实用价值</h3>
                        <p>验证了<span class="bold">严格的知识工程</span>方法为知识密集型学术环境中的可信<span class="bold">GenAI辅助</span>提供了<span class="bold">实用且可扩展的路径</span>。</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Multi-LLM Knowledge Distillation Research. All rights reserved.</p>
            <p>Contact: zhangnianheng2002@foxmail.com | Department of EEE, the University of Hong Kong</p>
        </div>
    </footer>

    <script>
        let currentLang = 'en';

        function toggleLanguage() {
            const langText = document.getElementById('langText');
            const enElements = document.querySelectorAll('[id^="en-"]');
            const zhElements = document.querySelectorAll('[id^="zh-"]');
            
            if (currentLang === 'en') {
                currentLang = 'zh';
                langText.textContent = 'English';
                enElements.forEach(el => el.classList.remove('active'));
                zhElements.forEach(el => el.classList.add('active'));
            } else {
                currentLang = 'en';
                langText.textContent = '中文';
                zhElements.forEach(el => el.classList.remove('active'));
                enElements.forEach(el => el.classList.add('active'));
            }
        }

        // Methodology tab switching
        document.querySelectorAll('.methodology-tab').forEach(tab => {
            tab.addEventListener('click', function() {
                const tabNumber = this.getAttribute('data-tab');
                
                // Remove active class from all tabs and images
                document.querySelectorAll('.methodology-tab').forEach(t => t.classList.remove('active'));
                document.querySelectorAll('.methodology-image').forEach(img => img.classList.remove('active'));
                
                // Add active class to clicked tab and corresponding image
                this.classList.add('active');
                document.querySelector(`.methodology-image[data-image="${tabNumber}"]`).classList.add('active');
            });
        });

        // Video player functionality
        function playVideo(element) {
            const videoContainer = element.parentNode;
            
            // 替换为实际视频路径
            // 视频文件建议放在 ./videos/ 文件夹中，文件名如 demo_video.mp4
            const videoHTML = `
                <video class="video-player" controls autoplay>
                    <source src="./videos/demo_video.mp4" type="video/mp4">
                    <source src="./videos/demo_video.webm" type="video/webm">
                    Your browser does not support the video tag.
                </video>
            `;
            
            // 根据当前语言更新视频说明文字
            const caption = currentLang === 'en' ? 
                'Interactive Demo of knowledge retrieval and responses by chatbots that use two knowledge bases. On the left is a chatbot using the baseline knowledge base, while on the right is a chatbot using our Proposed Q&A knowledge base.' : 
                '使用两个知识库的聊天机器人进行知识检索和回复的互动演示。左侧为使用基础知识库的聊天机器人，右侧为使用我们提出问答对知识库的聊天机器人';
                
            videoContainer.innerHTML = videoHTML + `<div class="image-caption">${caption}</div>`;
        }

        // Smooth scrolling for navigation links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                const headerHeight = document.querySelector('.header').offsetHeight;
                const targetPosition = target.offsetTop - headerHeight;
                
                window.scrollTo({
                    top: targetPosition,
                    behavior: 'smooth'
                });
            });
        });

        // Intersection Observer for animations
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, observerOptions);

        document.querySelectorAll('.section').forEach(section => {
            observer.observe(section);
        });

        // Initialize first methodology tab as active
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelector('.methodology-tab[data-tab="1"]').classList.add('active');
            document.querySelector('.methodology-image[data-image="1"]').classList.add('active');
        });
    </script>
</body>
</html>
